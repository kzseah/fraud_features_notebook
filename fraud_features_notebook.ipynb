{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e2cf127",
   "metadata": {},
   "source": [
    "# Fraud Feature Engineering — Runnable Notebook\n",
    "\n",
    "This notebook demonstrates four examples from the book-style snippets:\n",
    "\n",
    "A) IP vs Billing Country Mismatch (SQL + pandas)\n",
    "\n",
    "B) Count distinct cards seen per IP (SQL + pandas)\n",
    "\n",
    "C) Transactions per rolling window (sliding window) — using pandas to mimic SQL window RANGE\n",
    "\n",
    "D) New device & first_seen logic (SQL + pandas)\n",
    "\n",
    "Each section contains the **Postgres SQL** you would run in production (as a reference) followed by an executable pandas implementation on mock data so you can run it locally.\n",
    "\n",
    "At the end the notebook is saved to `/mnt/data/fraud_features_notebook.ipynb` and you can download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588c3540",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create mock tables: transactions, users, ip_geo, devices\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Helper to create timestamps\n",
    "base = datetime(2025, 9, 24, 10, 0, 0)\n",
    "\n",
    "# Create transactions for 5 users with various times, IPs, cards, devices\n",
    "rows = []\n",
    "users = ['u1','u2','u3','u4','u5']\n",
    "ips = ['1.2.3.4','1.2.3.5','203.0.113.5','198.51.100.12','10.0.0.5']\n",
    "cards = ['card_a','card_b','card_c','card_d','card_e','card_f']\n",
    "devices = ['dev1','dev2','dev3','dev4','dev5','dev6']\n",
    "\n",
    "for uid in users:\n",
    "    # create between 6 to 12 txns per user, spread across 0-30 minutes\n",
    "    n = np.random.randint(6,13)\n",
    "    for i in range(n):\n",
    "        tx_time = base + timedelta(minutes=int(np.random.exponential(scale=6)))\n",
    "        rows.append({\n",
    "            'transaction_id': f\"tx_{uid}_{i}\",\n",
    "            'user_id': uid,\n",
    "            'tx_time': tx_time,\n",
    "            'amount': float(np.random.choice([10,20,30,50,100,200,500], p=[0.2,0.2,0.15,0.2,0.15,0.05,0.05])),\n",
    "            'ip': np.random.choice(ips, p=[0.25,0.1,0.3,0.2,0.15]),\n",
    "            'card_hash': np.random.choice(cards),\n",
    "            'device_id': np.random.choice(devices)\n",
    "        })\n",
    "\n",
    "transactions = pd.DataFrame(rows)\n",
    "# Ensure tx_time sorted per user\n",
    "transactions = transactions.sort_values(['user_id','tx_time']).reset_index(drop=True)\n",
    "\n",
    "# Users table with billing_country\n",
    "users_df = pd.DataFrame({\n",
    "    'user_id': users,\n",
    "    'billing_country': ['MY','MY','SG','MY','ID']\n",
    "})\n",
    "\n",
    "# ip_geo mapping\n",
    "ip_geo = pd.DataFrame({\n",
    "    'ip': ips,\n",
    "    'country': ['SG','SG','MY','US','MY'],\n",
    "    'asn': ['AS100','AS100','AS200','AS300','AS200']\n",
    "})\n",
    "\n",
    "# devices table (simulate some devices first seen earlier)\n",
    "device_first = transactions.groupby('device_id')['tx_time'].min().reset_index().rename(columns={'tx_time':'first_seen'})\n",
    "device_first['first_seen'] = device_first['first_seen'] - pd.to_timedelta(np.random.randint(0,48,size=len(device_first)), unit='h')\n",
    "\n",
    "# show the created dataframes\n",
    "transactions.head(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681a4833",
   "metadata": {},
   "source": [
    "## A — IP vs Billing Country Mismatch\n",
    "\n",
    "### Postgres SQL (production reference)\n",
    "\n",
    "```sql\n",
    "-- Feature: ip_billing_mismatch (boolean)\n",
    "SELECT\n",
    "  t.transaction_id,\n",
    "  t.user_id,\n",
    "  t.tx_time,\n",
    "  t.ip,\n",
    "  ipg.country AS ip_country,\n",
    "  u.billing_country,\n",
    "  (ipg.country IS DISTINCT FROM u.billing_country) AS ip_billing_mismatch\n",
    "FROM transactions t\n",
    "LEFT JOIN ip_geo ipg ON t.ip = ipg.ip\n",
    "LEFT JOIN users u ON t.user_id = u.user_id\n",
    "    \n",
    "WHERE t.tx_time BETWEEN CURRENT_DATE - INTERVAL '30 days' AND CURRENT_DATE;\n",
    "```\n",
    "\n",
    "### pandas implementation (executable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a15c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute ip_billing_mismatch in pandas\n",
    "merged = transactions.merge(ip_geo, on='ip', how='left').merge(users_df, on='user_id', how='left')\n",
    "merged['ip_billing_mismatch'] = merged['country'] != merged['billing_country']\n",
    "# Treat NaN (unknown ip geo) as False for mismatch for this example; in production you may treat nulls specially\n",
    "merged['ip_billing_mismatch'] = merged['ip_billing_mismatch'].fillna(False)\n",
    "merged[['transaction_id','user_id','tx_time','ip','country','billing_country','ip_billing_mismatch']].head(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cb556a",
   "metadata": {},
   "source": [
    "## B — Count distinct cards seen per IP\n",
    "\n",
    "### Postgres SQL (production reference)\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "  t.ip,\n",
    "  COUNT(DISTINCT t.card_hash) AS distinct_cards_seen,\n",
    "  COUNT(*) AS tx_count_30d\n",
    "FROM transactions t\n",
    "WHERE t.tx_time >= NOW() - INTERVAL '30 days'\n",
    "GROUP BY t.ip\n",
    "HAVING COUNT(DISTINCT t.card_hash) > 2\n",
    "ORDER BY distinct_cards_seen DESC;\n",
    "```\n",
    "\n",
    "### pandas implementation (executable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90627e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count distinct cards per IP (last 30 days simulated here with full df)\n",
    "ip_agg = transactions.groupby('ip').agg(\n",
    "    distinct_cards_seen = ('card_hash','nunique'),\n",
    "    tx_count_30d = ('transaction_id','count')\n",
    ").reset_index().sort_values('distinct_cards_seen', ascending=False)\n",
    "ip_agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30429bc4",
   "metadata": {},
   "source": [
    "## C — Transactions per rolling window (sliding window)\n",
    "\n",
    "### Postgres SQL (production reference)\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "  t.*,\n",
    "  COUNT(*) OVER (\n",
    "    PARTITION BY user_id\n",
    "    ORDER BY tx_time\n",
    "    RANGE BETWEEN INTERVAL '10 minutes' PRECEDING AND CURRENT ROW\n",
    "  ) AS txn_count_last_10min\n",
    "FROM transactions t\n",
    "WHERE tx_time >= now() - interval '14 days';\n",
    "```\n",
    "\n",
    "### pandas implementation (executable):\n",
    "We compute, per user, the count of transactions in the 10-minute window ending at each transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be769567",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute rolling 10-minute count per user using pandas.\n",
    "df = transactions.copy()\n",
    "df['tx_time'] = pd.to_datetime(df['tx_time'])\n",
    "\n",
    "def rolling_count_10min(group):\n",
    "    # set time index\n",
    "    g = group.set_index('tx_time').sort_index()\n",
    "    # rolling count over 10 minute window\n",
    "    # use '10min' window on the index and count rows\n",
    "    g['txn_count_last_10min'] = g['amount'].rolling('10min').count().astype(int)\n",
    "    return g.reset_index()\n",
    "\n",
    "df_roll = df.groupby('user_id', group_keys=False).apply(rolling_count_10min).reset_index(drop=True)\n",
    "df_roll[['transaction_id','user_id','tx_time','amount','txn_count_last_10min']].head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29221ac9",
   "metadata": {},
   "source": [
    "## D — New device & first_seen logic\n",
    "\n",
    "### Postgres SQL (production reference)\n",
    "\n",
    "```sql\n",
    "WITH device_first AS (\n",
    "  SELECT device_id, MIN(tx_time) AS first_seen\n",
    "  FROM transactions\n",
    "  GROUP BY device_id\n",
    "    )\n",
    "SELECT t.transaction_id, t.user_id, t.device_id, t.amount, d.first_seen,\n",
    "       (t.tx_time - d.first_seen) < INTERVAL '24 hours' AS device_new_last_24h\n",
    "FROM transactions t\n",
    "LEFT JOIN device_first d USING (device_id)\n",
    "WHERE t.tx_time >= NOW() - INTERVAL '7 days'\n",
    "  AND (t.tx_time - d.first_seen) < INTERVAL '24 hours'\n",
    "  AND t.amount > 300;\n",
    "```\n",
    "\n",
    "### pandas implementation (executable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute device first_seen and flag transactions where device is new in last 24h and amount > threshold\n",
    "df = transactions.copy()\n",
    "df['tx_time'] = pd.to_datetime(df['tx_time'])\n",
    "\n",
    "device_first = df.groupby('device_id').agg(first_seen=('tx_time','min')).reset_index()\n",
    "\n",
    "df_dev = df.merge(device_first, on='device_id', how='left')\n",
    "df_dev['device_age_hours'] = (df_dev['tx_time'] - df_dev['first_seen']).dt.total_seconds() / 3600.0\n",
    "df_dev['device_new_last_24h'] = df_dev['device_age_hours'] < 24\n",
    "# show transactions that are new-device and amount > 300\n",
    "df_dev_filtered = df_dev[(df_dev['device_new_last_24h']) & (df_dev['amount'] > 300)]\n",
    "df_dev_filtered[['transaction_id','user_id','device_id','tx_time','amount','first_seen','device_age_hours','device_new_last_24h']].head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0bc74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the notebook programmatically (the nbformat part already assembled)\n",
    "print(\"This notebook will be saved by the driver code that constructed it.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
